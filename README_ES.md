# Events Service

## RFC ‚Äì Integraci√≥n de Eventos del Proveedor Externo en el Marketplace

**Autor:** Manuel S√°nchez del Campo  
**Fecha:** 06-02-2025  
**Revisi√≥n:** 1.0  
**Estado:** Borrador / En revisi√≥n

## √çndice

1. [Introducci√≥n](#introducci√≥n)
2. [Antecedentes y Contexto](#antecedentes-y-contexto)
3. [Objetivos](#objetivos)
4. [Alcance](#alcance)
5. [Descripci√≥n del Problema](#descripci√≥n-del-problema)
6. [Estrategia de Persistencia y Caching](#estrategia-de-persistencia-y-caching)
   - [PostgreSQL como Fuente de Verdad](#postgresql-como-fuente-de-verdad)
   - [Redis como Capa de Cach√©](#redis-como-capa-de-cach√©)
   - [Integraci√≥n de Ambas Soluciones](#integraci√≥n-de-ambas-soluciones)
7. [Decisi√≥n Arquitect√≥nica del Microservicio](#decisi√≥n-arquitect√≥nica-del-microservicio)
   - [Arquitectura Hexagonal](#arquitectura-hexagonal-ports--adapters)
   - [Dise√±o Basado en Dominio (DDD)](#dise√±o-basado-en-dominio-ddd---domain-driven-design)
   - [Patr√≥n CQRS Simplificado](#patr√≥n-cqrs-simplificado)
   - [Persistencia con PostgreSQL](#persistencia-con-postgresql)
   - [Capa de Cach√© con Redis](#capa-de-cach√©-con-redis)
   - [Integraci√≥n con el Proveedor Externo](#integraci√≥n-con-el-proveedor-externo)
   - [Resiliencia y Manejo de Errores](#resiliencia-y-manejo-de-errores)
   - [Escalabilidad y Despliegue](#escalabilidad-y-despliegue)
   - [Beneficios ante los Requisitos](#beneficios-ante-los-requisitos)
8. [Enfoque de Despliegue: Contenedores y Alternativas](#enfoque-de-despliegue-contenedores-y-alternativas)
9. [Consideraciones Adicionales](#consideraciones-adicionales)
10. [Extra Mile: Escalabilidad y Rendimiento](#extra-mile)
11. [Conclusi√≥n](#conclusi√≥n)

## 1. Introducci√≥n
Este documento describe la soluci√≥n propuesta para integrar los eventos provenientes de un proveedor externo en el marketplace. La soluci√≥n debe considerarse como un microservicio con pensamiento a largo plazo, permitiendo que futuros desarrolladores puedan mantener, escalar y evolucionar el c√≥digo sin dificultad. Se abordar√°n aspectos de persistencia, cach√© distribuido, comunicaci√≥n entre microservicios, despliegue en contenedores y estrategias de actualizaci√≥n de datos.

## 2. Antecedentes y Contexto
Se dispone de un marketplace de eventos en constante crecimiento y se encuentra en una fase de expansi√≥n continua para incorporar nuevos proveedores. En este contexto, el desaf√≠o consiste en desarrollar un microservicio que cumpla con los siguientes objetivos:

### Integraci√≥n de Datos Externos
- Obtener los eventos de un proveedor externo en formato XML.
- Garantizar la correcta extracci√≥n y normalizaci√≥n de la informaci√≥n.

### Persistencia y Actualizaci√≥n Constante
- Almacenar de forma persistente la informaci√≥n recibida para mantener un hist√≥rico actualizado.
- Mantener la base de datos sincronizada con la fuente externa.
- Reflejar los cambios en tiempo real, actualizando el estado de los eventos seg√∫n la disponibilidad indicada por el proveedor.

### Exposici√≥n de Eventos Activos
- El endpoint `/search` debe exponer √∫nicamente aquellos eventos activos.
- Solo se mostrar√°n eventos en "sell mode online" y que est√©n activos por el proveedor al momento de la consulta.

### Rendimiento y Resiliencia
- Garantizar tiempos de respuesta en el orden de cientos de milisegundos.
- Implementar estrategias de caching y una arquitectura robusta.
- Asegurar la disponibilidad del servicio incluso en presencia de fallos o retrasos en la comunicaci√≥n con el proveedor externo.

### Arquitectura Robusta y Escalable
- Implementar un patr√≥n arquitect√≥nico que facilite la escalabilidad, modularidad y mantenibilidad del servicio en el tiempo.
- Asegurar que la soluci√≥n pueda adaptarse a futuros cambios sin afectar el rendimiento o la estabilidad.

El endpoint del proveedor es:

```
https://provider.code-challenge.feverup.com/api/events
```

## 3. Objetivos

- **Integraci√≥n y Normalizaci√≥n:** Obtener, parsear y normalizar los eventos y zonas del XML del proveedor.
- **Persistencia:** Almacenar la informaci√≥n en una base de datos (source-of-truth) con consultas optimizadas mediante √≠ndices y/o vistas materializadas.
- **Cach√© Distribuido:** Implementar una capa de cach√© utilizando el patr√≥n Cache-Aside, para reducir la latencia del endpoint `/search` en escenarios de alta carga (picos de 5k a 10k RPS).
- **Endpoint de B√∫squeda:** Exponer un endpoint REST que, utilizando par√°metros `starts_at` y `ends_at`, devuelva los eventos vigentes con sus datos normalizados.
- **Sincronizaci√≥n As√≠ncrona:** Desarrollar un proceso configurable que sincronice peri√≥dicamente la informaci√≥n con el proveedor, realizando inserciones, actualizaciones y desactivaciones (upsert).
- **Despliegue en Contenedores:** Utilizar Docker y Docker Compose para el entorno de desarrollo, con posibilidad de migraci√≥n a entornos orquestados en producci√≥n.

## 4. Alcance
Este RFC cubre la definici√≥n y estrategias de:

- Consumo y procesamiento del XML del proveedor.
- Persistencia (modelado de datos, √≠ndices y estrategias de actualizaci√≥n).
- Cach√© distribuido para el endpoint `/search`.
- Definici√≥n de endpoints y estrategias de consulta (incluyendo validaciones y manejo de errores).
- Estrategia de sincronizaci√≥n y actualizaci√≥n (comparativa entre diferentes estrategias y explicaci√≥n de la estrategia seleccionada).

## 5. Descripci√≥n del Problema

### Desaf√≠os

- **Consumo y Procesamiento:** El proveedor ofrece un XML con eventos. Los eventos que dejan de estar disponibles no se incluyen en la respuesta.
- **Identificaci√≥n de Eventos:** Se recomienda utilizar `base_event_id` como identificador √∫nico.
- **Manejo de Zonas Duplicadas:** Consolidaci√≥n de informaci√≥n cuando `zone_id` se repite dentro de un evento.
- **Temporalidad y Rango:** El endpoint `/search` deber√° aceptar par√°metros `starts_at` y `ends_at` y devolver exclusivamente los eventos que coincidan dentro de este rango de fechas, tengan un `sell_mode` online y que se encuentren activos en el momento de la consulta.
- **Rendimiento y Resiliencia:** Garantizar respuestas en el orden de cientos de milisegundos mediante el uso de una arquitectura que combine un gestor de base de datos optimizado y un sistema de cache, asegurando as√≠ la disponibilidad y rapidez del endpoint  `search` sin depender de la latencia o disponibilidad del proveedor externo.
- **Sincronizaci√≥n:** Job as√≠ncrono con frecuencia configurable.

## 6. Estrategia de Persistencia y Caching

### 6.1. PostgreSQL como Fuente de Verdad

#### Almacenamiento Persistente
PostgreSQL se utilizar√° para guardar la informaci√≥n completa de los eventos y sus zonas. Es la base de datos de registro principal (*source-of-truth*), donde se registrar√°n:

- **Datos de eventos**: Identificadores, t√≠tulos, fechas, per√≠odos de venta, etc.
- **Datos de zonas asociadas**: Capacidad, precio, etc.

#### Optimizaci√≥n de Consultas

- **√çndices**: Se crear√°n √≠ndices en campos cr√≠ticos como `event_start_date` y `event_end_date` para facilitar la consulta por rangos de fechas.
- **Consultas Eficientes**: Se dise√±ar√°n consultas SQL optimizadas para que el filtrado por fechas sea r√°pido, aprovechando los √≠ndices y, de ser necesario, vistas materializadas en escenarios complejos.

#### Escalabilidad de Lectura

En un escenario de alta carga, se puede optar por:
- **R√©plicas de lectura**: Configurar r√©plicas de PostgreSQL para distribuir la carga de consultas, manteniendo la consistencia de los datos a trav√©s de replicaci√≥n as√≠ncrona.

---

### 6.2. Redis como Capa de Cach√©

#### Prop√≥sito del Cach√©

Redis actuar√° como un cach√© en memoria para reducir la latencia en el endpoint `/search` y disminuir la carga directa sobre PostgreSQL. Dado que se esperan picos de tr√°fico de **5k a 10k RPS**, el cach√© es clave para responder en el orden de **cientos de milisegundos**.

#### Patr√≥n de Cache Aside

Se utilizar√° el patr√≥n *cache-aside*:

1. **Consulta Inicial**: Cuando llega una petici√≥n al endpoint, se verifica si existe un resultado cacheado en Redis para el conjunto de par√°metros (`starts_at` y `ends_at`).
2. **Cache Hit**: Si existe, se devuelve el resultado de Redis inmediatamente.
3. **Cache Miss**: Si no existe, se consulta PostgreSQL, se procesa la respuesta y se almacena el resultado en Redis con un **TTL (time-to-live)** apropiado.

#### Invalidaci√≥n del Cach√©

- La actualizaci√≥n de datos se realiza a trav√©s de un **job as√≠ncrono** que sincroniza la informaci√≥n con el proveedor externo.
- Tras actualizar PostgreSQL, se pueden **invalidar o refrescar** las entradas de cach√© relacionadas (por ejemplo, mediante eventos o simplemente con **TTLs cortos** en el cach√© que garanticen que la informaci√≥n no quede obsoleta durante mucho tiempo).

#### Configuraci√≥n de Redis

- Se pueden definir **pol√≠ticas de expiraci√≥n** en funci√≥n de la naturaleza de los datos.
- Dado que la sincronizaci√≥n se ejecuta cada ciertos minutos, un **TTL de 1 a 5 minutos** para las claves cacheadas podr√≠a ser razonable.
- En escenarios de picos, Redis se encargar√° de absorber la mayor√≠a de las lecturas, asegurando que la consulta a la base de datos solo se produzca en caso de **cache miss**.

---

### 6.3. Integraci√≥n de Ambas Soluciones

### Flujo General

#### **Actualizaci√≥n de Datos**

1. Un proceso as√≠ncrono (**job o scheduler**) consume el XML del proveedor y actualiza PostgreSQL.
2. Tras la actualizaci√≥n, se invalidan o refrescan las claves de cach√© que puedan estar afectadas.

#### **Consulta del Endpoint `/search`**

1. Al recibir una solicitud, el sistema consulta Redis usando una **clave compuesta** (por ejemplo, hash de los par√°metros `starts_at` y `ends_at`).
2. **Si el valor existe en cach√©**, se devuelve inmediatamente.
3. **Si no existe**, se consulta PostgreSQL, se genera la respuesta y se almacena en Redis.

#### Beneficios

- **Baja Latencia**: Redis permite respuestas en tiempos muy bajos (**sub-100 ms**) en escenarios de alto tr√°fico.
- **Resiliencia**: El endpoint sigue respondiendo r√°pidamente incluso si hay retrasos en el *job* de sincronizaci√≥n o en la actualizaci√≥n de la base de datos.
- **Escalabilidad**: La combinaci√≥n de un **RDBMS** y una **capa de cach√© distribuida** permite manejar el escalado tanto a nivel de base de datos como a nivel de la aplicaci√≥n.

### 6.4 Diagrama del Flujo 

Flujo de llamada a `/search`

```mermaid
sequenceDiagram
    participant C as Cliente
    participant R as Controlador REST
    participant RC as Redis Cache
    participant PG as PostgreSQL
    participant P as Procesador

    C->>R: GET /search?starts_at=X&ends_at=Y
    R->>RC: Verificar cache
    alt Resultado en cache
        RC-->>R: Devolver resultado cacheado
    else Cache miss
        R->>PG: Consultar eventos
        PG-->>R: Devolver resultados
        R->>P: Procesar y formatear resultados
        P-->>R: Resultados formateados
        R->>RC: Almacenar en cache (con TTL)
    end
    R->>C: Devolver resultado al cliente
```

Flujo del proceso de sincronizacion de datos desde el cliente y persistencia
```mermaid
sequenceDiagram
   participant S as Scheduler/Job
   participant P as Proveedor Externo
   participant X as Parser XML
   participant DB as PostgreSQL
   participant RC as Redis Cache
   
       S->>P: Solicitar eventos (GET /api/events)
       alt Respuesta exitosa
           P-->>S: Devolver XML de eventos
           S->>X: Parsear XML
           X->>S: Eventos y zonas parseados
           loop Para cada evento
               S->>DB: Verificar existencia del evento
               alt Evento existe
                   S->>DB: Actualizar evento y zonas
               else Evento no existe
                   S->>DB: Insertar nuevo evento y zonas
               end
               S->>RC: Invalidar/Actualizar cache
           end
       else Error en la respuesta
           S->>S: Registrar error y programar reintento
       end
       S->>S: Finalizar ciclo de sincronizaci√≥n
```

## 7. An√°lisis de Estrategia para Actualizaci√≥n de Eventos en la BD

### Estrategia 1: Consulta Selectiva de IDs y Bulk Update para Inactivar Eventos Obsoletos

#### Pasos:

1. **Consulta ligera**: Se realiza una consulta para obtener √∫nicamente los identificadores (IDs) de los eventos activos del proveedor.
2. **C√°lculo de diferencia**: Se crea un conjunto de IDs que est√°n en la base de datos pero no en la lista del proveedor (obsoletos).
3. **Bulk update**: Se ejecuta una operaci√≥n en bloque que actualiza el campo `active` a `false` para esos IDs.
4. **Upsert de eventos del proveedor**: Se insertan o actualizan los eventos recibidos, marc√°ndolos como `active = true`.

#### Ventajas:

- **Eficiencia en la consulta**: La consulta de IDs es muy ligera y r√°pida, consumiendo poco ancho de banda y memoria.
- **Optimizaci√≥n en la BD**: El bulk update de IDs obsoletos es una operaci√≥n eficiente en el motor de la base de datos.
- **Menor carga en la capa de aplicaci√≥n**: Se evita traer objetos completos, reduciendo la memoria y el procesamiento en la capa de negocio.

#### Desventajas:

- **Complejidad en la l√≥gica**: Se requieren m√©todos adicionales en el repositorio y c√°lculos de diferencia en la aplicaci√≥n.
- **Dependencia en la consistencia de los IDs**: Es crucial garantizar que los IDs sean √∫nicos y bien indexados.

---

### Estrategia 2: Actualizaci√≥n Directa de la BD Sin Recuperar IDs

#### Pasos:

1. **Bulk Inactivation Directo**: Se ejecuta una consulta que marca `active = false` para todos los eventos en la BD cuyo `baseEventId` no se encuentre en la lista del proveedor.
2. **Upsert de eventos del proveedor**: Se insertan o actualizan los eventos recibidos, estableciendo `active = true`.

#### Ventajas:

- **Simplicidad en la implementaci√≥n**: Se evita traer IDs y calcular la diferencia en la aplicaci√≥n.
- **Mantenimiento m√°s sencillo**: Se reducen los pasos intermedios en la l√≥gica de actualizaci√≥n.

#### Desventajas:

- **Carga en la BD**: Si la tabla es grande, la consulta con `WHERE base_event_id NOT IN (...)` podr√≠a ser costosa.
- **Complejidad en la Query SQL**: Requiere optimizaci√≥n si el feed es extenso.

---

### Comparaci√≥n Final

| Criterio            | Estrategia 1 | Estrategia 2 |
|---------------------|-------------|-------------|
| **Simplicidad**     | Mayor complejidad en la capa de aplicaci√≥n | L√≥gica m√°s sencilla |
| **Rapidez**         | M√°s eficiente con grandes vol√∫menes de datos | Puede ser m√°s costosa en consultas grandes |
| **Carga en la BD**  | Optimiza la carga con consultas ligeras | Requiere evaluar todos los registros activos |
| **Escalabilidad**   | M√°s eficiente en bases de datos grandes | Depende de la optimizaci√≥n de la query |

---

### Conclusi√≥n

Dado un entorno con sincronizaci√≥n frecuente y gran volumen de registros, se recomienda **Estrategia 1: Consulta Selectiva de IDs y Bulk Update para Inactivar Eventos Obsoletos**, ya que:

- **Optimiza el procesamiento** al reducir la cantidad de datos transferidos y delegar la actualizaci√≥n en bloque al motor de la base de datos.
- **Mejora la escalabilidad y eficiencia**, al actualizar solo los eventos obsoletos en lugar de comparar todos los registros activos.
- **Reduce la carga en la aplicaci√≥n**, evitando transferencias de objetos completos y trabajando solo con identificadores.

Si bien la **Estrategia 2** es m√°s sencilla de implementar, su mayor carga en la base de datos la hace menos adecuada en escenarios de gran volumen y alta concurrencia.

### 8. Decisi√≥n Arquitect√≥nica del Microservicio

#### Enfoque General

El microservicio ha sido dise√±ado siguiendo principios de **modularidad, escalabilidad y mantenibilidad**. La arquitectura elegida permite una evoluci√≥n √°gil del sistema, facilitando la incorporaci√≥n de nuevas funcionalidades sin afectar su estabilidad. Se prioriz√≥ una estructura desacoplada para garantizar que cada componente pueda ser modificado o reemplazado sin impacto en el resto del sistema.

### Principales Decisiones

#### **1. Arquitectura Hexagonal (Ports & Adapters)**

Se ha adoptado una **arquitectura hexagonal**, tambi√©n conocida como **Puertos y Adaptadores**, debido a sus ventajas en t√©rminos de:

- **Separaci√≥n de preocupaciones:** La l√≥gica de negocio est√° completamente aislada de los detalles de infraestructura y frameworks, promoviendo una estructura limpia y modular.
- **Flexibilidad y Adaptabilidad:** Facilita el reemplazo de tecnolog√≠as o proveedores sin afectar la l√≥gica de negocio.
- **Testabilidad mejorada:** Permite realizar pruebas unitarias y de integraci√≥n de manera m√°s eficiente, sin dependencias de infraestructura.
- **Independencia tecnol√≥gica:** Evita acoplamientos con frameworks espec√≠ficos, asegurando mayor longevidad del c√≥digo.

La estructura del servicio se organiza en las siguientes capas:

- **Dominio:** Contiene las reglas de negocio centrales y modelos de datos.
- **Aplicaci√≥n:** Define los casos de uso mediante puertos de entrada (*Input Ports*), asegurando que la l√≥gica de negocio est√© desacoplada de la implementaci√≥n concreta.
- **Infraestructura:** Implementa los adaptadores para interactuar con bases de datos, sistemas de cach√© y APIs externas a trav√©s de puertos de salida (*Output Ports*).

#### **2. Dise√±o Basado en Dominio (DDD - Domain-Driven Design)**

Se han aplicado principios de **Domain-Driven Design (DDD)** para modelar el dominio del servicio:

- **Entidades y Agregados:** Se han definido modelos claros como `Event` y `Zone`, asegurando la integridad de los datos y la coherencia en las operaciones.
- **Servicios de Dominio:** La l√≥gica de negocio se encapsula en servicios de dominio que implementan reglas espec√≠ficas del negocio de eventos.

#### **3. Patr√≥n CQRS Simplificado**

Se ha implementado una versi√≥n simplificada de **Command Query Responsibility Segregation (CQRS)** para mejorar el rendimiento y escalabilidad:

- **Consultas optimizadas:** La recuperaci√≥n de datos utiliza √≠ndices y cach√© distribuido para mejorar la eficiencia.
- **Separaci√≥n de responsabilidades:** Las operaciones de consulta (`search`) y escritura (`sync`) est√°n desacopladas, permitiendo optimizar cada proceso de manera independiente.

#### **4. Persistencia con PostgreSQL**

- Se ha elegido **PostgreSQL** como base de datos principal, aprovechando sus capacidades de indexaci√≥n y escalabilidad. .
- **Flyway** gestiona la versi√≥n de esquemas y migraciones de datos.

#### **5. Capa de Cach√© con Redis**

Para reducir la latencia en la consulta de eventos activos, se ha implementado una **capa de cach√© distribuida** basada en **Redis**, siguiendo un patr√≥n **Cache-Aside**:

- **Consultas r√°pidas:** Permite respuestas en milisegundos sin acceder a la base de datos en cada solicitud.
- **TTL din√°mico:** Se configura un tiempo de vida adecuado para evitar inconsistencias en datos desactualizados.
- **Invalidaci√≥n eficiente:** La cach√© se refresca tras cada ciclo de sincronizaci√≥n con el proveedor externo.

#### **6. Integraci√≥n con el Proveedor Externo**

- Se utiliza **Retrofit** para el consumo de la API del proveedor externo, garantizando una integraci√≥n robusta y flexible.
- Se implementan mecanismos de **reintento autom√°tico y circuit breaker** con **Resilience4j** para manejar fallos en la comunicaci√≥n.
- La sincronizaci√≥n se realiza de manera **as√≠ncrona y configurable**, asegurando que la informaci√≥n de eventos est√© siempre actualizada.

#### **7. Resiliencia y Manejo de Errores**

Para garantizar la estabilidad del servicio ante fallos externos o problemas de conectividad:

- **Resilience4j** gestiona **circuit breakers, retries y bulkheads**, mejorando la tolerancia a fallos.
- **Monitoreo con Prometheus y Grafana**, permitiendo visualizar m√©tricas clave y detectar posibles cuellos de botella.
- **Logs estructurados con SLF4J y Logback**, facilitando la trazabilidad de errores.

#### **8. Escalabilidad y Despliegue**

El servicio est√° dise√±ado para soportar escalabilidad horizontal y despliegue en entornos productivos mediante **Docker y Kubernetes**:

- **Contenedores Docker:** Facilitan el despliegue y replicaci√≥n del servicio.
- **Gesti√≥n centralizada de logs y m√©tricas** con herramientas como **ELK Stack o Prometheus/Grafana**.

### Beneficios ante los Requisitos

| Requisito                         | Beneficio de la Arquitectura |
|-----------------------------------|------------------------------|
| **Alta Disponibilidad y Resiliencia** | Redis permite respuestas r√°pidas y Resilience4j mitiga fallos en APIs externas. |
| **Escalabilidad** | El dise√±o modular facilitan la escalabilidad horizontal. |
| **Mantenibilidad** | La arquitectura hexagonal separa responsabilidades, simplificando la evoluci√≥n del c√≥digo. |
| **Integraci√≥n con el Proveedor** | Retrofit y mecanismos de resiliencia garantizan una comunicaci√≥n robusta. |
| **Optimizaci√≥n de Consultas** | PostgreSQL con √≠ndices mejora el rendimiento de b√∫squeda. |

### Conclusi√≥n

Esta arquitectura **ofrece una base s√≥lida para el crecimiento y mantenimiento del sistema**, aline√°ndose con las mejores pr√°cticas de dise√±o y garantizando flexibilidad, escalabilidad y rendimiento √≥ptimo. La separaci√≥n de capas y la adopci√≥n de est√°ndares modernos permiten un desarrollo sostenible a largo plazo, asegurando que el microservicio pueda evolucionar sin comprometer su estabilidad ni su eficiencia.

## 8. Enfoque de Despliegue: Contenedores y Alternativas

#### 8.1 Uso de Docker y Docker Compose
- Microservicio: Spring Boot + PostgreSQL + Redis en contenedores.
- Entorno de desarrollo reproducible.

#### 8.2 Propuesta de alternativas para Producci√≥n
- **Kubernetes:** Escalabilidad y gesti√≥n avanzada.
- **Servicios en la Nube:** Amazon RDS y Amazon ElastiCache.


## 9. Consideraciones Adicionales
- **Configurabilidad de la Sincronizaci√≥n:** Frecuencia ajustable en el futuro.
- **Manejo de Zonas Duplicadas:** Consolidaci√≥n de datos.
- **Conversi√≥n de Fechas:** Manejo con zona horaria definida.

## 10. Extra Mile: Escalabilidad y Rendimiento
Aunque la soluci√≥n propuesta cumple con los requisitos planteados y ofrece una base s√≥lida, es importante considerar estrategias adicionales para escalar la aplicaci√≥n y mejorar su rendimiento en escenarios reales. A continuaci√≥n, se describen algunas recomendaciones y enfoques que se pueden aplicar para lograr una mayor escalabilidad y capacidad de respuesta, especialmente cuando se trabaja con archivos que contienen miles de eventos y cientos de zonas, y con picos de tr√°fico de entre 5k y 10k peticiones por segundo.

### 1. Optimizaci√≥n y Escalado de la Persistencia

#### R√©plicas de Lectura en PostgreSQL
Configurar r√©plicas de lectura para distribuir la carga de consultas puede mejorar significativamente el rendimiento del endpoint `/search`. Las r√©plicas permiten que las consultas se sirvan desde instancias separadas, reduciendo la presi√≥n sobre la base de datos principal y mejorando la capacidad de respuesta durante picos de tr√°fico.

#### Uso de Vistas Materializadas
En escenarios donde la consulta de eventos requiere realizar c√°lculos complejos o unir m√∫ltiples tablas, el uso de vistas materializadas puede acelerar el procesamiento de las consultas. Estas vistas se pueden actualizar de forma peri√≥dica, ofreciendo un balance entre la frescura de los datos y el rendimiento.

### 2. Despliegue y Orquestaci√≥n en Entornos de Producci√≥n

#### Migraci√≥n a Kubernetes
Aunque Docker Compose es adecuado para entornos de desarrollo y pruebas, en producci√≥n se recomienda el uso de Kubernetes para:

- **Autoscaling:** Configurar escalado horizontal autom√°tico (Horizontal Pod Autoscaler) para ajustarse din√°micamente a la carga de tr√°fico.
- **Gesti√≥n de Configuraciones y Secretos:** Utilizar un patron de **configuraci√≥n centralizada** para administrar las configuraciones y credenciales, permitiendo cambios din√°micos sin necesidad de redeploy.

#### Balanceo de Carga y CDN
Utilizar balanceadores de carga robustos y considerar la implementaci√≥n de una CDN (Content Delivery Network) para distribuir el tr√°fico y mejorar la latencia global, especialmente en entornos geogr√°ficamente dispersos.

### 3. Monitoreo y Tuning en Tiempo Real

#### Herramientas de Monitoreo
Implementar soluciones de monitoreo (como Datadog y openSearch / Prometheus, Grafana y ELK Stack) para observar el comportamiento del sistema en tiempo real. Esto incluye m√©tricas de rendimiento de la base de datos, uso de memoria en Redis, tiempos de respuesta del endpoint y la carga en cada microservicio.

### 4. Consideraciones Adicionales

#### Optimizaci√≥n de la L√≥gica de Negocio
Revisar peri√≥dicamente la l√≥gica de procesamiento y actualizaci√≥n de eventos para identificar oportunidades de optimizaci√≥n, especialmente en la consolidaci√≥n de zonas duplicadas y en la validaci√≥n de datos.

#### Estrategia de Desacoplamiento
Continuar utilizando la arquitectura hexagonal para mantener el desacoplamiento entre la l√≥gica de negocio y las dependencias tecnol√≥gicas. Esto facilita la incorporaci√≥n de nuevas tecnolog√≠as y permite que cada componente escale de forma independiente.

Estas estrategias garantizar√°n que la aplicaci√≥n se mantenga operativa y eficiente, incluso en condiciones de carga extrema.

## 11. Conclusi√≥n
Esta soluci√≥n proporciona una arquitectura escalable, eficiente y mantenible para la integraci√≥n de eventos del proveedor externo en el marketplace.


# üöÄ Events Service - Setup Guide

Este documento explica c√≥mo configurar y ejecutar **Events Service** en tu entorno local.

## üìå Prerrequisitos
Antes de comenzar, aseg√∫rate de tener instalado lo siguiente:

- **Java Development Kit (JDK) 17 o posterior** 
- **Maven 3.6 o posterior** 
- **PostgreSQL 13 o posterior** 
- **Docker y Docker Compose** 

---

## 1Ô∏è‚É£ Clonar el repositorio
Ejecuta los siguientes comandos para clonar el proyecto:

```bash
git clone https://github.com/FeverCodeChallenge/manuel.sanchez.git
cd manuel.sanchez
```

---

## 2Ô∏è‚É£ Configurar las propiedades de la aplicaci√≥n
La aplicaci√≥n requiere configurar la conexi√≥n a la base de datos y otros servicios.

### üîπ Configuraci√≥n actual (desarrollo)
Actualmente, los par√°metros de configuraci√≥n est√°n definidos expl√≠citamente en el archivo `application.properties`, ya que la aplicaci√≥n est√° en fase de desarrollo.
Para ejecutar la aplicaci√≥n localmente, edita el archivo y actualiza las credenciales de la base de datos:

```properties
spring.datasource.url=jdbc:postgresql://localhost:5432/fever_events
spring.datasource.username=tu_usuario
spring.datasource.password=tu_contrase√±a
```

### ‚ö†Ô∏è Recomendaci√≥n para entornos de producci√≥n
Por seguridad, **NO** se recomienda almacenar credenciales sensibles en archivos de configuraci√≥n. En lugar de esto, usa **variables de entorno** o un **gestor de secretos** (como Vault, AWS Secrets Manager, Azure Key Vault, etc.).

---

## 3Ô∏è‚É£ Levantar servicios con Docker
Antes de compilar y ejecutar la aplicaci√≥n, es necesario iniciar **PostgreSQL y Redis** usando `docker-compose`:

```bash
docker-compose up -d
```

‚úÖ **IMPORTANTE**: Este paso es obligatorio antes de ejecutar `mvn clean install`, ya que la aplicaci√≥n necesita PostgreSQL y Redis para funcionar.

Para verificar que los servicios est√°n corriendo:

```bash
docker ps
```

Si necesitas detener los servicios:

```bash
docker-compose down
```
üí° Nota sobre futuras mejoras en los tests
En una pr√≥xima fase de desarrollo, se debe modificar la configuraci√≥n de los tests para utilizar una base de datos en memoria que simule el comportamiento de PostgreSQL (por ejemplo, Testcontainers o H2 con dialecto PostgreSQL). Esto permitir√° ejecutar las pruebas sin necesidad de tener PostgreSQL y Redis en ejecuci√≥n, mejorando la portabilidad y automatizaci√≥n del proceso de pruebas.
---

## 4Ô∏è‚É£ Construir la aplicaci√≥n

Una vez levantados los servicios con Docker, compila el proyecto con:

```bash
mvn clean install
```

---

## 5Ô∏è‚É£ Ejecutar la aplicaci√≥n

### üîπ Opci√≥n 1: Ejecutar localmente

Ejecuta la aplicaci√≥n en tu m√°quina:

```bash
mvn spring-boot:run
```

La aplicaci√≥n estar√° disponible en:
üìå [http://localhost:8080](http://localhost:8080)

### üîπ Opci√≥n 2: Ejecutar con Docker
Si prefieres ejecutar la aplicaci√≥n dentro de un contenedor Docker:

#### Construir la imagen Docker:
```bash
docker build -t fever-events-service .
```

#### Ejecutar el contenedor:
```bash
docker run -p 8080:8080 fever-events-service
```

---

## 6Ô∏è‚É£ Ejecutar pruebas
Ejecuta los tests unitarios y de integraci√≥n con:

```bash
mvn test
```

üìù **Nota**: Si los tests fallan por problemas de conexi√≥n con PostgreSQL o Redis, aseg√∫rate de que `docker-compose` est√° corriendo.

---

## 7Ô∏è‚É£ Migraciones de Base de Datos (Flyway)
La aplicaci√≥n usa **Flyway** para gestionar las migraciones de la base de datos.

- Las migraciones se ejecutan autom√°ticamente al iniciar la aplicaci√≥n.
- Si necesitas aplicarlas manualmente, usa:

```bash
mvn flyway:migrate
```

### üîπ Limpiar la base de datos y aplicar migraciones desde cero
Si hay errores con las migraciones, puedes limpiar y reaplicar todas:

```bash
mvn flyway:clean
mvn flyway:migrate
```

---

## 8Ô∏è‚É£ Monitoreo y Salud de la Aplicaci√≥n
La aplicaci√≥n expone endpoints para verificar su estado:

- **Estado de salud**: [http://localhost:8080/actuator/health](http://localhost:8080/actuator/health)

---

## 9Ô∏è‚É£ Documentaci√≥n de la API (Swagger)
Para ver la documentaci√≥n interactiva de la API, accede a:

üìå [http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html)

Esto te permitir√° explorar y probar los endpoints f√°cilmente.

---

## üõ†Ô∏è Soluci√≥n de Problemas

### üîπ PostgreSQL no se conecta
Si ves un error como:

```pgsql
Connection to localhost:5432 refused. Check that the hostname and port are correct.
```
**Soluci√≥n**: Aseg√∫rate de que PostgreSQL est√° corriendo con:
```bash
docker-compose up -d
```

### üîπ Redis no est√° disponible
Si ves un error relacionado con Redis:

```pgsql
Cannot connect to Redis on localhost:6379.
```
**Soluci√≥n**: Aseg√∫rate de que Redis est√° corriendo con:
```bash
docker-compose up -d
```

### üîπ Errores en las migraciones de Flyway
Si Flyway falla al iniciar:

```bash
mvn flyway:clean
mvn flyway:migrate
```

---

## üéØ Resumen del proceso

| Paso | Acci√≥n |
|------|--------|
| 1Ô∏è‚É£ | Clonar el repositorio (`git clone`) |
| 2Ô∏è‚É£ | Configurar `application.properties` |
| 3Ô∏è‚É£ | Levantar `docker-compose up -d` |
| 4Ô∏è‚É£ | Compilar con `mvn clean install` |
| 5Ô∏è‚É£ | Ejecutar la aplicaci√≥n (`mvn spring-boot:run` o con Docker) |
| 6Ô∏è‚É£ | Ejecutar los tests (`mvn test`) |
| 7Ô∏è‚É£ | Verificar migraciones (`mvn flyway:migrate`) |
| 8Ô∏è‚É£ | Monitorear la aplicaci√≥n (`/actuator/health`, `/actuator/metrics`) |
| 9Ô∏è‚É£ | Acceder a la API en [Swagger UI](http://localhost:8080/swagger-ui.html) |

---

## üöÄ Conclusi√≥n
Esta gu√≠a te permite configurar y ejecutar **Events Service** de forma clara y estructurada.
Si sigues estos pasos en orden, evitar√°s errores y facilitar√°s la ejecuci√≥n de la aplicaci√≥n. üî•üöÄ


